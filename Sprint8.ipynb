{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sprint8.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNcc/0qY64x1RDBmAIXP3US",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nklbigone/DIC-ML/blob/main/Sprint8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJI0s7WFFZ2V"
      },
      "source": [
        "# importing dependencies\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import datasets"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "PSjpNnYkHjIP",
        "outputId": "7be9cf71-be01-438c-b5e6-40e0b5d1a905"
      },
      "source": [
        "# importing dataset\n",
        "data=pd.read_csv('train.csv').select_dtypes(include='number')\n",
        "\n",
        "# handling of missing values\n",
        "data.isnull().sum()\n",
        "data = data.fillna(data.mean())\n",
        "data.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>LowQualFinSF</th>\n",
              "      <th>GrLivArea</th>\n",
              "      <th>BsmtFullBath</th>\n",
              "      <th>BsmtHalfBath</th>\n",
              "      <th>FullBath</th>\n",
              "      <th>HalfBath</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>KitchenAbvGr</th>\n",
              "      <th>TotRmsAbvGrd</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <th>GarageCars</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2003</td>\n",
              "      <td>2003</td>\n",
              "      <td>196.0</td>\n",
              "      <td>706</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>856</td>\n",
              "      <td>856</td>\n",
              "      <td>854</td>\n",
              "      <td>0</td>\n",
              "      <td>1710</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>2003.0</td>\n",
              "      <td>2</td>\n",
              "      <td>548</td>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>1976</td>\n",
              "      <td>1976</td>\n",
              "      <td>0.0</td>\n",
              "      <td>978</td>\n",
              "      <td>0</td>\n",
              "      <td>284</td>\n",
              "      <td>1262</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1976.0</td>\n",
              "      <td>2</td>\n",
              "      <td>460</td>\n",
              "      <td>298</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>60</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2001</td>\n",
              "      <td>2002</td>\n",
              "      <td>162.0</td>\n",
              "      <td>486</td>\n",
              "      <td>0</td>\n",
              "      <td>434</td>\n",
              "      <td>920</td>\n",
              "      <td>920</td>\n",
              "      <td>866</td>\n",
              "      <td>0</td>\n",
              "      <td>1786</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>2001.0</td>\n",
              "      <td>2</td>\n",
              "      <td>608</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>70</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1915</td>\n",
              "      <td>1970</td>\n",
              "      <td>0.0</td>\n",
              "      <td>216</td>\n",
              "      <td>0</td>\n",
              "      <td>540</td>\n",
              "      <td>756</td>\n",
              "      <td>961</td>\n",
              "      <td>756</td>\n",
              "      <td>0</td>\n",
              "      <td>1717</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1998.0</td>\n",
              "      <td>3</td>\n",
              "      <td>642</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>272</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>60</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>350.0</td>\n",
              "      <td>655</td>\n",
              "      <td>0</td>\n",
              "      <td>490</td>\n",
              "      <td>1145</td>\n",
              "      <td>1145</td>\n",
              "      <td>1053</td>\n",
              "      <td>0</td>\n",
              "      <td>2198</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>836</td>\n",
              "      <td>192</td>\n",
              "      <td>84</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  MSSubClass  LotFrontage  LotArea  ...  MiscVal  MoSold  YrSold  SalePrice\n",
              "0   1          60         65.0     8450  ...        0       2    2008     208500\n",
              "1   2          20         80.0     9600  ...        0       5    2007     181500\n",
              "2   3          60         68.0    11250  ...        0       9    2008     223500\n",
              "3   4          70         60.0     9550  ...        0       2    2006     140000\n",
              "4   5          60         84.0    14260  ...        0      12    2008     250000\n",
              "\n",
              "[5 rows x 38 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzMPzu15IUho",
        "outputId": "06c81272-3a93-4ec1-99db-2e606bb7bcaf"
      },
      "source": [
        "# splitting the data\n",
        "X = data.drop(['SalePrice'],axis=1).values\n",
        "y = data['SalePrice'].values\n",
        "\n",
        "X = np.log1p(X)\n",
        "y = np.log1p(y)\n",
        "\n",
        "print('X shape:{}, y shape:{}'.format(X.shape,y.shape))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X shape:(1460, 37), y shape:(1460,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5daLua9IkEE"
      },
      "source": [
        "## **[Problem 1] Blending scratch mounting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFx-qfhfInBd",
        "outputId": "fc91c7bd-1290-4a53-c692-f5b2fd08b834"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=1)\n",
        "print('X_train shape:{}, y_test shape:{}'.format(X_train.shape,y_test.shape))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape:(1168, 37), y_test shape:(292,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTDdfnzFKmRB",
        "outputId": "361e9cf5-f672-4adb-9928-877a735742bc"
      },
      "source": [
        "# example 1\n",
        "models = [LinearRegression(),SVR(),DecisionTreeRegressor()]\n",
        "predictions = list()\n",
        "for model in models:\n",
        "    model.fit(X_train,y_train)\n",
        "    predictions.append(model.predict(X_test))\n",
        "    \n",
        "predictions_ndarray = np.array(predictions)\n",
        "blend = np.mean(predictions_ndarray,axis=0)\n",
        "print('MSE blend:{:.3f}'.format(mean_squared_error(y_test,blend)))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE blend:0.021\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfBlKP15LYTE",
        "outputId": "df87ba8a-1fa2-450f-e49a-582ab7aba13f"
      },
      "source": [
        "# example 2\n",
        "svr_model1 = SVR(C=1)\n",
        "svr_model2 = SVR(C=5)\n",
        "svr_model3 = SVR(C=10)\n",
        "svr_model1.fit(X_train,y_train)\n",
        "svr_model2.fit(X_train,y_train)\n",
        "svr_model3.fit(X_train,y_train)\n",
        "svr_pred1 = svr_model1.predict(X_test)\n",
        "svr_pred2 = svr_model2.predict(X_test)\n",
        "svr_pred3 = svr_model2.predict(X_test)\n",
        "    \n",
        "svr_blend = np.mean([svr_pred1,svr_pred2,svr_pred3],axis=0)\n",
        "print('MSE blend:{:.3f}'.format(mean_squared_error(y_test,svr_blend)))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE blend:0.023\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSWrdqqWLfBs",
        "outputId": "f44a9a03-b70c-4b5e-f350-7bec492d0e71"
      },
      "source": [
        "# example 3\n",
        "std_scaler = StandardScaler()\n",
        "std_scaler.fit(X_train)\n",
        "X_train_trans = std_scaler.transform(X_train)\n",
        "X_test_trans = std_scaler.transform(X_test)\n",
        "\n",
        "models2 = [LinearRegression(),SVR(),DecisionTreeRegressor()]\n",
        "predictions2 = list()\n",
        "for model in models2:\n",
        "    model.fit(X_train_trans,y_train)\n",
        "    predictions2.append(model.predict(X_test_trans))\n",
        "    \n",
        "predictions_ndarray2 = np.array(predictions)\n",
        "blend2 = np.mean(predictions_ndarray2,axis=0)\n",
        "print('MSE blend:{:.3f}'.format(mean_squared_error(y_test,blend2)))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE blend:0.021\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnGJ58_dMQKR"
      },
      "source": [
        "## **[Problem 2] Scratch mounting of bagging**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erPVodgxMSvi",
        "outputId": "04af64f1-10f1-4f20-f8ac-dc708e7ccecc"
      },
      "source": [
        "X_train_bag, X_test_bag, y_train_bag, y_test_bag = train_test_split(X,y,test_size=0.2,shuffle=True)\n",
        "print('X_train shape:{}, y_test shape:{}'.format(X_train_bag.shape,y_test_bag.shape))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape:(1168, 37), y_test shape:(292,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gq1OPoDAMg4c",
        "outputId": "42a9a579-e093-4695-b84d-385c3ddfa188"
      },
      "source": [
        "models = [LinearRegression(),SVR(),DecisionTreeRegressor()]\n",
        "class BaggingScratch():\n",
        "    def __init__(self, models):\n",
        "        self.models = models\n",
        "        self.predictions = list()\n",
        "        \n",
        "    def fit(self,X,y):\n",
        "        for model in models:\n",
        "            model.fit(X,y)\n",
        "    def predict(self,X):\n",
        "        predictions = list()\n",
        "        for model in self.models:\n",
        "            prediction = model.predict(X)\n",
        "            predictions.append(prediction)\n",
        "        self.predictions = np.mean(np.array(predictions),axis=0)\n",
        "        return self.predictions\n",
        "    def mse(self, y):\n",
        "        mse = (mean_squared_error(y,self.predictions))\n",
        "        return mse\n",
        "    \n",
        "\n",
        "bag = BaggingScratch(models)\n",
        "bag.fit(X_train,y_train)\n",
        "print(\"average of bagging pred:{}\".format(bag.predict(X_test)))\n",
        "print(\"average of bagging mse:{:.3f}\".format(bag.mse(y_test)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "average of bagging pred:[12.23932577 12.02483747 11.56490218 11.01704575 11.95028506 12.60472669\n",
            " 12.56970405 11.86406303 12.27052756 12.40987263 12.07770492 11.0609977\n",
            " 12.18649386 12.82128078 12.35823762 11.590351   11.62240874 11.72839201\n",
            " 12.32107768 11.77422308 11.65550567 11.82571449 12.48142256 12.66660672\n",
            " 11.4749905  12.20612542 11.72834793 12.16198191 12.86494783 11.86085426\n",
            " 11.73072584 11.70222618 11.64786071 11.53485066 11.90581371 12.73189308\n",
            " 11.76620459 11.30574824 12.58250034 11.67492642 11.94849455 11.90182527\n",
            " 11.53293091 11.73911925 12.11921553 12.08552396 11.73163762 12.06724842\n",
            " 12.40174075 12.387204   11.5938642  12.64822509 11.50486925 12.34734819\n",
            " 12.25089831 11.51290754 11.67917674 12.03161852 11.74564378 12.13721745\n",
            " 12.05543542 12.53183387 11.48497146 11.56815769 12.03181347 11.78683765\n",
            " 11.74365605 12.3373183  12.07654313 11.94699061 12.16256299 11.49884952\n",
            " 12.64776829 11.95045468 12.01314801 12.27684283 12.04960477 11.86340477\n",
            " 12.90554184 12.22241589 12.2218487  11.74789516 11.79758841 12.01585735\n",
            " 12.19222809 12.03053068 11.99980867 12.04381338 12.14218659 12.09982482\n",
            " 12.20024787 11.98374621 11.59307713 11.49854593 11.79144265 11.75484805\n",
            " 11.67651947 11.80456354 11.95026297 11.88906072 11.98585921 11.80841032\n",
            " 11.63764146 11.64858042 11.79048556 12.14972015 12.11081098 12.1586146\n",
            " 11.92171686 12.66321646 11.92443487 12.10094728 11.90105268 12.16977428\n",
            " 12.38660575 12.04175793 12.30864661 11.75745901 12.03873256 12.50073588\n",
            " 11.87475675 12.29733837 12.74241422 11.95535723 12.20320309 12.14328756\n",
            " 12.60499457 11.64641506 12.24518592 12.26323617 12.49906312 11.41171568\n",
            " 11.76258843 11.80757526 11.47063079 12.2443827  13.01297117 12.68279786\n",
            " 12.3851558  11.83855143 11.71901215 12.54425055 12.15202436 12.18017725\n",
            " 11.53496742 12.12776861 11.49762479 12.15141199 12.34359973 11.60348324\n",
            " 12.12636599 12.02254067 11.69002493 12.11512468 12.16238571 12.62426532\n",
            " 11.5142385  11.83236935 11.45737406 11.80387283 10.8461882  11.49062511\n",
            " 11.93000881 11.88886631 11.62666707 11.79042723 11.98271453 11.84846931\n",
            " 11.88605889 11.58543379 12.35661599 11.87206539 12.31573002 12.53100769\n",
            " 12.22329101 11.81282669 12.23369901 12.17304408 11.82887715 12.0558039\n",
            " 11.8343862  12.06805951 11.91456029 11.89133242 12.56853011 11.92843727\n",
            " 12.5735829  12.58176614 12.05836336 11.70744783 11.53627764 11.93276551\n",
            " 11.47359134 12.22938049 11.77804349 12.45717787 12.33434989 11.97714181\n",
            " 11.88356441 11.03802792 12.23275246 12.35417099 12.10713942 12.08403982\n",
            " 12.43058494 11.7022267  12.1352952  12.59176048 12.40200476 12.36948621\n",
            " 12.20238901 11.63503197 11.97702499 11.6939772  12.55143408 12.44839643\n",
            " 11.70891099 11.37884673 12.17970052 11.13916403 13.00202785 11.68743647\n",
            " 11.93344705 12.21364068 11.69613085 11.72352883 12.17918392 12.05596463\n",
            " 11.94046769 12.02430028 11.66153402 12.10699923 11.56150125 11.73325161\n",
            " 12.64600432 11.67891512 12.57174256 11.68277489 11.79075479 12.60451988\n",
            " 12.72303774 12.06302374 11.8602322  11.95139059 11.82723683 11.63965374\n",
            " 11.96089235 11.8908257  11.98949411 11.98951354 11.63564484 11.59118072\n",
            " 12.10036455 12.08235329 11.6225595  11.66887091 12.14189883 11.39444332\n",
            " 12.62551884 11.76171701 12.22567728 12.15641717 12.2790291  12.06541047\n",
            " 11.58558014 12.23583858 11.77528161 12.13174608 11.89242056 11.4934439\n",
            " 12.09590801 12.11105321 11.38813463 11.66463707 12.11537418 11.40596943\n",
            " 11.67948348 11.80258618 11.95899572 11.91254344 11.8130794  11.81463453\n",
            " 11.77505609 11.93245587 12.37112628 12.44323496 11.71135554 11.35080043\n",
            " 12.36415426 11.48194682 11.37364782 12.51356676]\n",
            "average of bagging mse:0.022\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MnMbBbCMxu_"
      },
      "source": [
        "## **[Problem 3] Stacking scratch mounting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKUw-knMMwSV"
      },
      "source": [
        "def get_dataset():\n",
        "    X, y = datasets.make_classification(n_samples=10000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
        "    return X, y\n",
        "\n",
        "X, y = get_dataset()\n",
        "# splitting into train and tests(used for base models)\n",
        "X_train_full, X_test_1, y_train_full, y_test_1 = train_test_split(X,y,test_size=0.5,random_state=1)\n",
        "\n",
        "# splitting into train and validations(used for ensemble model)\n",
        "X_train_1, X_val, y_train_1, y_val = train_test_split(X_train_full,y_train_full,test_size=0.2,random_state=1)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgQesfB2PS-K"
      },
      "source": [
        "# a function to return the models in a form of a tuple\n",
        "def get_models():\n",
        "    models = list()\n",
        "    models.append(('lr',LinearRegression()))\n",
        "    models.append(('knn', KNeighborsClassifier()))\n",
        "    models.append(('cart', DecisionTreeRegressor()))\n",
        "    models.append(('bayes', GaussianNB()))\n",
        "    return models\n",
        "\n",
        "# a function to fit and blend all of our models\n",
        "def fit_ensemble(models, X_train_1, X_val, y_train_1, y_val):\n",
        "    # fit and predict using the validation data\n",
        "    \n",
        "    # a list to hold the predicted data from the base model for the blender model\n",
        "    meta_X = list()\n",
        "    \n",
        "    # loop through our models\n",
        "    for name,model in models:\n",
        "        model.fit(X_train_1, y_train_1)\n",
        "        y_pred = model.predict(X_val)\n",
        "        \n",
        "        # reshaping the predicted results into a matrix with one column\n",
        "        y_pred = y_pred.reshape(len(y_pred), 1)\n",
        "        meta_X.append(y_pred)\n",
        "        \n",
        "    meta_X = np.hstack(meta_X)\n",
        "    \n",
        "    # defining our blender\n",
        "    blender = LinearRegression()\n",
        "    \n",
        "    # fitting our blender using our meta values and y validation set\n",
        "    blender.fit(meta_X, y_val)\n",
        "    return blender\n",
        "\n",
        "# a function to make predictions with our ensemble\n",
        "def pred_ensemble(models, blender, X_test_1):\n",
        "    # a list to hold te predictions for the blender\n",
        "    meta_X = list()\n",
        "    \n",
        "    # loop through our models\n",
        "    for name,model in models:\n",
        "        \n",
        "        # predicting using our base models\n",
        "        y_pred = model.predict(X_test_1)\n",
        "        \n",
        "        # reshaping the predicted results into a matrix with one column\n",
        "        y_pred = y_pred.reshape(len(y_pred), 1)\n",
        "        meta_X.append(y_pred)\n",
        "        \n",
        "    meta_X = np.hstack(meta_X)\n",
        "    \n",
        "    # predicting using our blender\n",
        "    return blender.predict(meta_X)\n",
        "\n",
        "models = get_models()\n",
        "blender = fit_ensemble(models, X_train_1, X_val, y_train_1, y_val)\n",
        "y_pred = pred_ensemble(models, blender, X_test_1)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eh1zRnd3Para",
        "outputId": "57f3496a-7ebc-4ac7-eb6e-3124b50362e8"
      },
      "source": [
        "# printing mse\n",
        "print(\"Values used\")\n",
        "print(\"Train:{} Val:{} Test:{}\".format(X_train_1.shape, X_val.shape, X_test_1.shape))\n",
        "print(\"Accuracy score\")\n",
        "print(\"*\"*50)\n",
        "print(\"Blended ensemble:{:.3f}\".format(mean_squared_error(y_test_1,y_pred)))\n",
        "\n",
        "# on individual model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train_1, y_train_1)\n",
        "y_pred1= model.predict(X_test_1)\n",
        "print(\"Logistic regression:{:.3f}\".format(mean_squared_error(y_test_1,y_pred1)))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Values used\n",
            "Train:(4000, 20) Val:(1000, 20) Test:(5000, 20)\n",
            "Accuracy score\n",
            "**************************************************\n",
            "Blended ensemble:0.023\n",
            "Logistic regression:0.110\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}